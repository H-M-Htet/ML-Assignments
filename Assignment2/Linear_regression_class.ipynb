{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment tracking\n",
    "import mlflow\n",
    "import os\n",
    "# This the dockerized method.\n",
    "# We build two docker containers, one for python/jupyter and another for mlflow.\n",
    "# The url `mlflow` is resolved into another container within the same composer.\n",
    "mlflow.set_tracking_uri(\"http://localhost:8080\")\n",
    "# In the dockerized way, the user who runs this code will be `root`.\n",
    "# The MLflow will also log the run user_id as `root`.\n",
    "# To change that, we need to set this environ[\"LOGNAME\"] to your name.\n",
    "os.environ[\"LOGNAME\"] = \"HMH\"\n",
    "# mlflow.create_experiment(name=\"chaky-diabetes-example\")  #create if you haven't create\n",
    "mlflow.set_experiment(experiment_name=\"HMH-regularization-example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "print(\"Features: \", diabetes.feature_names)\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "m = X.shape[0]  #number of samples\n",
    "n = X.shape[1]  #number of features\n",
    "\n",
    "#polynomial transformation\n",
    "# X   = PolynomialFeatures(degree = 3, include_bias=False).fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# actually you can do like this too\n",
    "# X = np.insert(X, 0, 1, axis=1)\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train   = np.concatenate((intercept, X_train), axis=1)\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "X_test    = np.concatenate((intercept, X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class LinearRegression(object):\n",
    "    \n",
    "    #in this class, we add cross validation as well for some spicy code....\n",
    "    kfold = KFold(n_splits=5)\n",
    "            \n",
    "    def __init__(self, regularization=None, lr=0.001, method='batch', num_epochs=500, batch_size=50, cv=kfold, use_momentum=False, momentum=0.0, init_method= 'xavier'): #mdified init_method\n",
    "        self.lr         = lr\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.method     = method\n",
    "        self.cv         = cv\n",
    "        self.use_momentum = use_momentum  # New flag to enable/disable momentum\n",
    "        self.momentum = momentum  # Momentum value\n",
    "        self.init_method = init_method\n",
    "        \n",
    "        self.regularization = regularization if regularization else NormalPenalty()\n",
    "    def mse(self, y_true, y_pred):\n",
    "        return ((y_pred - y_true) ** 2).sum() / y_true.shape[0]\n",
    "    \n",
    "    def r2(self, y_true, y_pred):\n",
    "   \n",
    "        ss_total = np.sum((y_true - np.mean(y_true)) ** 2)  # Total sum of squares\n",
    "        ss_residual = np.sum((y_true - y_pred) ** 2)  # Sum of squared residuals\n",
    "        return 1 - (ss_residual / ss_total)\n",
    "    \n",
    "    def xavier_init(self, input_dim):              #based on pseudocode, xavier initializing\n",
    "        lower, upper = -(1.0 / np.sqrt(input_dim)), (1.0 / np.sqrt(input_dim))\n",
    "        numbers = np.random.uniform(lower,upper, 1000)                 #gernerating 1000 random numbers between lower and upper\n",
    "        scaled = lower + numbers * (upper - lower)\n",
    "        \n",
    "        return scaled[:input_dim]\n",
    "    \n",
    "    \n",
    "# Fitting Polynomial Regression to the dataset\n",
    "#     from sklearn.preprocessing import PolynomialFeatures\n",
    " \n",
    "# poly = PolynomialFeatures(degree=4)\n",
    "# X_poly = poly.fit_transform(X)\n",
    " \n",
    "# poly.fit(X_train, y_train)\n",
    "# lin2 = LinearRegression()\n",
    "# lin2.fit(X_train, y_train)\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "            \n",
    "        #create a list of kfold scores\n",
    "        self.kfold_scores = list()\n",
    "        \n",
    "        #reset val loss\n",
    "        self.val_loss_old = np.inf\n",
    "\n",
    "        #kfold.split in the sklearn.....\n",
    "        #5 splits\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv.split(X_train)):\n",
    "            \n",
    "            X_cross_train = X_train[train_idx]\n",
    "            y_cross_train = y_train[train_idx]\n",
    "            X_cross_val   = X_train[val_idx]\n",
    "            y_cross_val   = y_train[val_idx]\n",
    "\n",
    "            if self.init_method == 'xavier':   #condition check to use xavier\n",
    "                self.theta = self.xavier_init(X_cross_train.shape[1]) \n",
    "            else:\n",
    "                self.theta = np.zeros(X_cross_train.shape[1]) #else use zeros\n",
    "                #self.theta = np.zeros(X_cross_train.shape[1], 1)\n",
    "            \n",
    "            #define X_cross_train as only a subset of the data\n",
    "            #how big is this subset?  => mini-batch size ==> 50\n",
    "            \n",
    "            #one epoch will exhaust the WHOLE training set\n",
    "            with mlflow.start_run(run_name=f\"Fold-{fold}\", nested=True):\n",
    "                \n",
    "                params = {\"method\": self.method, \"lr\": self.lr, \"reg\": type(self).__name__, \"init_method\": self.init_method, \"momentum\": self.momentum}\n",
    "                mlflow.log_params(params=params)\n",
    "                \n",
    "                for epoch in range(self.num_epochs):\n",
    "                    #val_loss_new =  None \n",
    "                \n",
    "                    #with replacement or no replacement\n",
    "                    #with replacement means just randomize\n",
    "                    #with no replacement means 0:50, 51:100, 101:150, ......300:323\n",
    "                    #shuffle your index\n",
    "                    perm = np.random.permutation(X_cross_train.shape[0])\n",
    "                            \n",
    "                    X_cross_train = X_cross_train[perm]\n",
    "                    y_cross_train = y_cross_train[perm]\n",
    "                    \n",
    "                    if self.method == 'sto':\n",
    "                        for batch_idx in range(X_cross_train.shape[0]):\n",
    "                            X_method_train = X_cross_train[batch_idx].reshape(1, -1) #(11,) ==> (1, 11) ==> (m, n)\n",
    "                            y_method_train = y_cross_train[batch_idx] \n",
    "                            train_loss = self._train(X_method_train, y_method_train)\n",
    "                    elif self.method == 'mini':\n",
    "                        for batch_idx in range(0, X_cross_train.shape[0], self.batch_size):\n",
    "                        #batch_idx = 0, 50, 100, 150\n",
    "                            X_method_train = X_cross_train[batch_idx:batch_idx+self.batch_size, :]\n",
    "                            y_method_train = y_cross_train[batch_idx:batch_idx+self.batch_size]\n",
    "                            train_loss = self._train(X_method_train, y_method_train)\n",
    "                    else:\n",
    "                        X_method_train = X_cross_train\n",
    "                        y_method_train = y_cross_train\n",
    "                        train_loss = self._train(X_method_train, y_method_train)\n",
    "\n",
    "                mlflow.log_metric(key=\"train_loss\", value=train_loss, step=epoch)\n",
    "\n",
    "                yhat_val = self.predict(X_cross_val)\n",
    "                val_loss_new = self.mse(y_cross_val, yhat_val)\n",
    "                mlflow.log_metric(key=\"val_loss\", value=val_loss_new, step=epoch)\n",
    "                    \n",
    "                #early stopping\n",
    "                if np.allclose(val_loss_new, self.val_loss_old):\n",
    "                    break\n",
    "                self.val_loss_old = val_loss_new\n",
    "\n",
    "                y_pred = self.predict(X_cross_val)          #compute and print r2_score after training\n",
    "                r2 = self.r2(y_cross_val, y_pred)\n",
    "                # print(f\"Fold {fold} - R² Score: {r2:.4f}\")\n",
    "            \n",
    "            self.kfold_scores.append(val_loss_new)\n",
    "            print(f\"Fold {fold}: {val_loss_new}\")\n",
    "            print(f\"Fold {fold} - R² Score: {r2:.4f}\")\n",
    "            \n",
    "                    \n",
    "    # def _train(self, X, y):\n",
    "    #     yhat = self.predict(X)\n",
    "    #     m    = X.shape[0]        \n",
    "    #     grad = (1/m) * X.T @(yhat - y) + self.regularization.derivation(self.theta)\n",
    "    #     self.theta = self.theta - self.lr * grad\n",
    "    #     return self.mse(y, yhat)\n",
    "    \n",
    "    def _train(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        m = X.shape[0]\n",
    "        grad = (1/m) * X.T @ (yhat - y) + self.regularization.derivation(self.theta)\n",
    "        \n",
    "        if not hasattr(self, 'prev_step'): # Initialize momentum if not set\n",
    "            self.prev_step = np.zeros_like(grad)\n",
    "\n",
    "        step = self.lr * grad   # Update weights using momentum\n",
    "\n",
    "        if self.use_momentum:\n",
    "            self.theta -= step + self.momentum * self.prev_step\n",
    "            self.prev_step = step  # Store the previous step for momentum\n",
    "        else:\n",
    "            self.theta -= step   #normal grad\n",
    "\n",
    "        return self.mse(y, yhat)\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return X @ self.theta  #===>(m, n) @ (n, )\n",
    "    \n",
    "    def _coef(self):\n",
    "        return self.theta[1:]  #remind that theta is (w0, w1, w2, w3, w4.....wn)\n",
    "                               #w0 is the bias or the intercept\n",
    "                               #w1....wn are the weights / coefficients / theta\n",
    "    def _bias(self):\n",
    "     return self.theta[0]\n",
    "    \n",
    "    def feature_importance_plot(self): #Plot the feature importance based on the coefficients (theta).\n",
    "    \n",
    "        # Extract the absolute values of the coefficients and sort them\n",
    "        # abs_coeff = np.abs(self.theta)\n",
    "        # sorted_idx = np.argsort(abs_coeff)[::-1]  # Sort in descending order\n",
    "        feature_names = [\"age\", \"sex\", \"bmi\", \"bp\"]\n",
    "        importance_values = [abs(self._coef()[0]), abs(self._coef()[1]), abs(self._coef()[2]), abs(self._coef()[3])]\n",
    "        # Plot the coefficients\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(feature_names, importance_values, color='green')\n",
    "        #plt.yticks(range(len(sorted_idx)), np.array(feature_names)[sorted_idx])\n",
    "        plt.xlabel('Feature Importance (Magnitude of Coefficient)')\n",
    "        plt.title('Feature Importance Based on Coefficients')\n",
    "        plt.gca().invert_yaxis()  # To show the largest importance at the top\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoPenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l # lambda value\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.abs(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * np.sign(theta)\n",
    "    \n",
    "class RidgePenalty:\n",
    "    \n",
    "    def __init__(self, l):\n",
    "        self.l = l\n",
    "        \n",
    "    def __call__(self, theta): #__call__ allows us to call class as method\n",
    "        return self.l * np.sum(np.square(theta))\n",
    "        \n",
    "    def derivation(self, theta):\n",
    "        return self.l * 2 * theta\n",
    "    \n",
    "class ElasticPenalty:\n",
    "    \n",
    "    def __init__(self, l = 0.1, l_ratio = 0.5):\n",
    "        self.l = l \n",
    "        self.l_ratio = l_ratio\n",
    "\n",
    "    def __call__(self, theta):  #__call__ allows us to call class as method\n",
    "        l1_contribution = self.l_ratio * self.l * np.sum(np.abs(theta))\n",
    "        l2_contribution = (1 - self.l_ratio) * self.l * 0.5 * np.sum(np.square(theta))\n",
    "        return (l1_contribution + l2_contribution)\n",
    "\n",
    "    def derivation(self, theta):\n",
    "        l1_derivation = self.l * self.l_ratio * np.sign(theta)\n",
    "        l2_derivation = self.l * (1 - self.l_ratio) * theta\n",
    "        return (l1_derivation + l2_derivation)\n",
    "    \n",
    "class PolynomialPenalty:\n",
    "    def __init__(self, l, p=1):\n",
    "        self.l, self.p = l, p\n",
    "    def __call__(self, theta): return self.l * np.sum(np.abs(theta)**self.p)\n",
    "    def derivation(self, theta): return self.l * self.p * np.sign(theta) * np.abs(theta)**(self.p-1)\n",
    "\n",
    "class NormalPenalty:\n",
    "    def __call__(self, theta): return 0\n",
    "    def derivation(self, theta): return np.zeros_like(theta)\n",
    "\n",
    "\n",
    "    \n",
    "class Lasso(LinearRegression):\n",
    "    \n",
    "    def __init__(self, method, lr, l=0.1, init_method='xavier', momentum=0.0):\n",
    "        self.regularization = LassoPenalty(l)\n",
    "        super().__init__(self.regularization, lr, method, init_method=init_method, momentum=momentum)\n",
    "        \n",
    "class Ridge(LinearRegression):\n",
    "    \n",
    "    def __init__(self, method, lr, l=0.1, init_method='xavier', momentum=0.0):\n",
    "        self.regularization = RidgePenalty(l)\n",
    "        super().__init__(self.regularization, lr, method, init_method=init_method, momentum=momentum)\n",
    "\n",
    "class Normal(LinearRegression):\n",
    "    def __init__(self, method, lr, init_method='xavier', momentum=0.0):\n",
    "        super().__init__(None, lr, method, init_method=init_method, momentum=momentum)\n",
    "        \n",
    "# class ElasticNet(LinearRegression):\n",
    "    \n",
    "#     def __init__(self, method, lr, l, l_ratio=0.5):\n",
    "#         self.regularization = ElasticPenalty(l, l_ratio)\n",
    "#         super().__init__(self.regularization, lr, method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for looping classnames\n",
    "import sys\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Running Ridge with Ridge, lr=0.01, Grad_method=stochastic,init=zeros, momentum=0.0, Poly_Dregree=True =====\n",
      "Fold 0: 3842.849510270647\n",
      "Fold 0 - R² Score: 0.3502\n",
      "Fold 1: 4651.545383106083\n",
      "Fold 1 - R² Score: 0.2201\n",
      "Fold 2: 3107.4700456591822\n",
      "Fold 2 - R² Score: 0.5107\n",
      "Fold 3: 2491.8465949436095\n",
      "Fold 3 - R² Score: 0.5097\n",
      "Fold 4: 4215.07897044458\n",
      "Fold 4 - R² Score: 0.3100\n",
      "Test MSE: 3585.2936, R² Score: 0.3773\n",
      "===== Running Ridge with Ridge, lr=0.001, Grad_method=stochastic,init=zeros, momentum=0.0, Poly_Dregree=True =====\n",
      "Fold 0: 13863.07155973834\n",
      "Fold 0 - R² Score: -1.3442\n",
      "Fold 1: 15613.089020647043\n",
      "Fold 1 - R² Score: -1.6176\n",
      "Fold 2: 10582.780564110797\n",
      "Fold 2 - R² Score: -0.6664\n",
      "Fold 3: 9156.573167843597\n",
      "Fold 3 - R² Score: -0.8015\n",
      "Fold 4: 13454.44739498861\n",
      "Fold 4 - R² Score: -1.2025\n",
      "Test MSE: 12162.4915, R² Score: -1.1123\n",
      "===== Running Ridge with Ridge, lr=0.0001, Grad_method=stochastic,init=zeros, momentum=0.0, Poly_Dregree=True =====\n",
      "Fold 0: 28028.135591356615\n",
      "Fold 0 - R² Score: -3.7394\n",
      "Fold 1: 31127.16249230919\n",
      "Fold 1 - R² Score: -4.2186\n",
      "Fold 2: 23313.405404666504\n",
      "Fold 2 - R² Score: -2.6710\n",
      "Fold 3: 21729.847891043428\n",
      "Fold 3 - R² Score: -3.2753\n",
      "Fold 4: 26356.1783413549\n",
      "Fold 4 - R² Score: -3.3145\n",
      "Test MSE: 26144.2191, R² Score: -3.5405\n",
      "===== Running Ridge with Ridge, lr=0.01, Grad_method=stochastic,init=zeros, momentum=0.9, Poly_Dregree=True =====\n",
      "Fold 0: 3842.849510270647\n",
      "Fold 0 - R² Score: 0.3502\n",
      "Fold 1: 4651.545383106083\n",
      "Fold 1 - R² Score: 0.2201\n",
      "Fold 2: 3107.4700456591822\n",
      "Fold 2 - R² Score: 0.5107\n",
      "Fold 3: 2491.8465949436095\n",
      "Fold 3 - R² Score: 0.5097\n",
      "Fold 4: 4215.07897044458\n",
      "Fold 4 - R² Score: 0.3100\n",
      "Test MSE: 3585.2936, R² Score: 0.3773\n",
      "===== Running Ridge with Ridge, lr=0.001, Grad_method=stochastic,init=zeros, momentum=0.9, Poly_Dregree=True =====\n",
      "Fold 0: 13863.07155973834\n",
      "Fold 0 - R² Score: -1.3442\n",
      "Fold 1: 15613.089020647045\n",
      "Fold 1 - R² Score: -1.6176\n",
      "Fold 2: 10582.780564110797\n",
      "Fold 2 - R² Score: -0.6664\n",
      "Fold 3: 9156.5731678436\n",
      "Fold 3 - R² Score: -0.8015\n",
      "Fold 4: 13454.44739498861\n",
      "Fold 4 - R² Score: -1.2025\n",
      "Test MSE: 12162.4915, R² Score: -1.1123\n",
      "===== Running Ridge with Ridge, lr=0.0001, Grad_method=stochastic,init=zeros, momentum=0.9, Poly_Dregree=True =====\n",
      "Fold 0: 28028.135591356615\n",
      "Fold 0 - R² Score: -3.7394\n",
      "Fold 1: 31127.16249230919\n",
      "Fold 1 - R² Score: -4.2186\n",
      "Fold 2: 23313.405404666504\n",
      "Fold 2 - R² Score: -2.6710\n",
      "Fold 3: 21729.847891043428\n",
      "Fold 3 - R² Score: -3.2753\n",
      "Fold 4: 26356.1783413549\n",
      "Fold 4 - R² Score: -3.3145\n",
      "Test MSE: 26144.2191, R² Score: -3.5405\n",
      "===== Running Ridge with Ridge, lr=0.01, Grad_method=stochastic,init=xavier, momentum=0.0, Poly_Dregree=True =====\n",
      "Fold 0: 3842.849510270647\n",
      "Fold 0 - R² Score: 0.3502\n",
      "Fold 1: 4651.545383106083\n",
      "Fold 1 - R² Score: 0.2201\n",
      "Fold 2: 3107.4700456591827\n",
      "Fold 2 - R² Score: 0.5107\n",
      "Fold 3: 2491.8465949436095\n",
      "Fold 3 - R² Score: 0.5097\n",
      "Fold 4: 4215.0789704445815\n",
      "Fold 4 - R² Score: 0.3100\n",
      "Test MSE: 3585.2936, R² Score: 0.3773\n",
      "===== Running Ridge with Ridge, lr=0.001, Grad_method=stochastic,init=xavier, momentum=0.0, Poly_Dregree=True =====\n",
      "Fold 0: 13863.07155973834\n",
      "Fold 0 - R² Score: -1.3442\n",
      "Fold 1: 15613.089020647043\n",
      "Fold 1 - R² Score: -1.6176\n",
      "Fold 2: 10582.780564110797\n",
      "Fold 2 - R² Score: -0.6664\n",
      "Fold 3: 9156.573167843597\n",
      "Fold 3 - R² Score: -0.8015\n",
      "Fold 4: 13454.447394988614\n",
      "Fold 4 - R² Score: -1.2025\n",
      "Test MSE: 12162.4915, R² Score: -1.1123\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Log the model\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         signature \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39minfer_signature(X_train_used, model\u001b[38;5;241m.\u001b[39mpredict(X_train_used))\n\u001b[1;32m---> 82\u001b[0m         \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m         mlflow\u001b[38;5;241m.\u001b[39mend_run()\n",
      "File \u001b[1;32md:\\AIT_Second_sem\\ML\\Assignments\\ML-Assignments\\Assignment1\\.venv\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:413\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;129m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[38;5;241m.\u001b[39mformat(package_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscikit-learn\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mlog_model\u001b[39m(\n\u001b[0;32m    336\u001b[0m     sk_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m ):\n\u001b[0;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;124;03m    containing the following flavors:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m \n\u001b[0;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msklearn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43msk_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msk_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserialization_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserialization_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpyfunc_predict_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\AIT_Second_sem\\ML\\Assignments\\ML-Assignments\\Assignment1\\.venv\\Lib\\site-packages\\mlflow\\models\\model.py:796\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\u001b[0m\n\u001b[0;32m    792\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mtracking\u001b[38;5;241m.\u001b[39mfluent\u001b[38;5;241m.\u001b[39m_get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m    793\u001b[0m mlflow_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[0;32m    794\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39martifact_path, run_id\u001b[38;5;241m=\u001b[39mrun_id, metadata\u001b[38;5;241m=\u001b[39mmetadata, resources\u001b[38;5;241m=\u001b[39mresources\n\u001b[0;32m    795\u001b[0m )\n\u001b[1;32m--> 796\u001b[0m \u001b[43mflavor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result in\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;66;03m# __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path)\u001b[38;5;241m.\u001b[39mrglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pycache__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\AIT_Second_sem\\ML\\Assignments\\ML-Assignments\\Assignment1\\.venv\\Lib\\site-packages\\mlflow\\sklearn\\__init__.py:305\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(sk_model, path, conda_env, code_paths, mlflow_model, serialization_format, signature, input_example, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001b[0m\n\u001b[0;32m    302\u001b[0m     default_reqs \u001b[38;5;241m=\u001b[39m get_default_pip_requirements(include_cloudpickle)\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;66;03m# To ensure `_load_pyfunc` can successfully load the model during the dependency\u001b[39;00m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;66;03m# inference, `mlflow_model.save` must be called beforehand to save an MLmodel file.\u001b[39;00m\n\u001b[1;32m--> 305\u001b[0m     inferred_reqs \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_pip_requirements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_data_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mFLAVOR_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m     default_reqs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mset\u001b[39m(inferred_reqs)\u001b[38;5;241m.\u001b[39munion(default_reqs))\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\AIT_Second_sem\\ML\\Assignments\\ML-Assignments\\Assignment1\\.venv\\Lib\\site-packages\\mlflow\\utils\\environment.py:430\u001b[0m, in \u001b[0;36minfer_pip_requirements\u001b[1;34m(model_uri, flavor, fallback, timeout, extra_env_vars)\u001b[0m\n\u001b[0;32m    426\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m _infer_requirements(\n\u001b[0;32m    427\u001b[0m                 model_uri, flavor, raise_on_error\u001b[38;5;241m=\u001b[39mraise_on_error, extra_env_vars\u001b[38;5;241m=\u001b[39mextra_env_vars\n\u001b[0;32m    428\u001b[0m             )\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 430\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_infer_requirements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_on_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_on_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_env_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_env_vars\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_error \u001b[38;5;129;01mor\u001b[39;00m (fallback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32md:\\AIT_Second_sem\\ML\\Assignments\\ML-Assignments\\Assignment1\\.venv\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:511\u001b[0m, in \u001b[0;36m_infer_requirements\u001b[1;34m(model_uri, flavor, raise_on_error, extra_env_vars)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _PYPI_PACKAGE_INDEX \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    509\u001b[0m     _PYPI_PACKAGE_INDEX \u001b[38;5;241m=\u001b[39m _load_pypi_package_index()\n\u001b[1;32m--> 511\u001b[0m modules \u001b[38;5;241m=\u001b[39m \u001b[43m_capture_imported_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_env_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_env_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m packages \u001b[38;5;241m=\u001b[39m _flatten([_MODULES_TO_PACKAGES\u001b[38;5;241m.\u001b[39mget(module, []) \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules])\n\u001b[0;32m    513\u001b[0m packages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(_normalize_package_name, packages)\n",
      "File \u001b[1;32md:\\AIT_Second_sem\\ML\\Assignments\\ML-Assignments\\Assignment1\\.venv\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:385\u001b[0m, in \u001b[0;36m_capture_imported_modules\u001b[1;34m(model_uri, flavor, record_full_module, extra_env_vars)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _capture_modules\n\u001b[0;32m    384\u001b[0m error_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmpdir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 385\u001b[0m \u001b[43m_run_command\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_capture_modules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--model-path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--flavor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--output-file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--error-file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m--sys-path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrecord_full_module_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocess_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmain_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_MLFLOW_IN_CAPTURE_MODULE_PROCESS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_env_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(error_file):\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(error_file) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32md:\\AIT_Second_sem\\ML\\Assignments\\ML-Assignments\\Assignment1\\.venv\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:252\u001b[0m, in \u001b[0;36m_run_command\u001b[1;34m(cmd, timeout_seconds, env)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m     timer\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m--> 252\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    253\u001b[0m     stdout \u001b[38;5;241m=\u001b[39m stdout\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    254\u001b[0m     stderr \u001b[38;5;241m=\u001b[39m stderr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1211\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1208\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1211\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1630\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[1;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;66;03m# Wait for the reader threads, or time out.  If we time out, the\u001b[39;00m\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;66;03m# threads remain reading and the fds left open in case the user\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;66;03m# calls communicate again.\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1630\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_remaining_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m   1632\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, orig_timeout)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:1149\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\threading.py:1169\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1170\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1171\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Define the hyperparameters to loop over\n",
    "polynomials = [\"True\", \"False\"]\n",
    "regs = [\"Ridge\", \"Lasso\", \"Normal\"]\n",
    "grad_methods = [\"stochastic\", \"mini-batch\", \"batch\"]\n",
    "init_methods = [\"zeros\", \"xavier\"]\n",
    "momentum_options = [0.0, 0.9]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "\n",
    "POLY_DEGREE = 1 #PolynomialFeature_Transform_For_X_train_data\n",
    "poly_transformer = PolynomialFeatures(degree=POLY_DEGREE, include_bias=False)\n",
    "X_train_poly = poly_transformer.fit_transform(X_train)\n",
    "X_test_poly = poly_transformer.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# for poly in polynomial:\n",
    "# Run experiments\n",
    "for poly in polynomials: #outtest loop for Polynomial_regularization\n",
    "    for reg in regs:\n",
    "        for grad_method in grad_methods:\n",
    "            for init_method in init_methods:\n",
    "                for momentum in momentum_options:\n",
    "                    for lr in learning_rates:\n",
    "                    \n",
    "                        # print(\"=\"*35)\n",
    "                        # print(f\"Using Polynomial Degree: {POLY_DEGREE}\" if poly == \"True\" else \"Polynomial: False\")\n",
    "                        # print(f\"===== Regularization: {reg} =====\")\n",
    "                        # print(f\"===== Grad_method: {grad_method} =====\")\n",
    "                        # print(f\"===== Init_Method: {init_method} =====\")\n",
    "                        # print(f\"===== Momentum: {momentum} =====\")\n",
    "                        # print(f\"===== Learning Rate: {lr} =====\")\n",
    "                        # print(\"=\"*35)\n",
    "\n",
    "                        type_of_regression = str_to_class(reg)\n",
    "                        params = {\"method\": grad_method,\"lr\": lr,\"init_method\": init_methods,\"momentum\": momentum} # Set hyperparameters\n",
    "\n",
    "                        if poly == \"True\":\n",
    "                            X_train_used = X_train_poly\n",
    "                            X_test_used = X_test_poly\n",
    "                        else:\n",
    "                            X_train_used == X_train\n",
    "                            X_test_used == X_test\n",
    "\n",
    "\n",
    "                        with mlflow.start_run(run_name=f\"Reg-{reg}_LR-{lr}_Momentum-{momentum}_Init-{init_method}_Method-{grad_method}_poly--{poly}\", nested=True):\n",
    "\n",
    "                            print(f\"===== Running {reg} with {reg}, lr={lr}, Grad_method={grad_method},init={init_method}, momentum={momentum}, Poly_Dregree={poly} =====\")\n",
    "\n",
    "                    # if reg == \"Normal\":\n",
    "                    #     model = LinearRegression(**params)\n",
    "                    # # elif reg == \"Normal\":\n",
    "                    # #     model = LinearRegression(**params)\n",
    "                    # else:\n",
    "                    # # Get the correct regression type\n",
    "                            mlflow.log_params(params=params)      \n",
    "                            model = type_of_regression(**params)  \n",
    "\n",
    "                    # Train the model\n",
    "                            model.fit(X_train_used, y_train)\n",
    "\n",
    "                    # Make predictions\n",
    "                            yhat = model.predict(X_test_used)\n",
    "\n",
    "                    # Compute metrics\n",
    "                            mse = model.mse(y_test, yhat)\n",
    "                            r2 = model.r2(y_test, yhat)\n",
    "\n",
    "                            print(f\"Test MSE: {mse:.4f}, R² Score: {r2:.4f}\")\n",
    "\n",
    "                        # Log metrics in MLflow\n",
    "                            mlflow.log_params(params)\n",
    "                            mlflow.log_metric(\"Test MSE\", mse)\n",
    "                            mlflow.log_metric(\"Test R²\", r2)\n",
    "\n",
    "                    # Log the model\n",
    "                            signature = mlflow.models.infer_signature(X_train_used, model.predict(X_train_used))\n",
    "                            mlflow.sklearn.log_model(model, artifact_path='model', signature=signature)\n",
    "\n",
    "                            mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_used.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_importance_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 170\u001b[0m, in \u001b[0;36mLinearRegression.feature_importance_plot\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m importance_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coef()[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coef()[\u001b[38;5;241m1\u001b[39m]), \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coef()[\u001b[38;5;241m2\u001b[39m]), \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coef()[\u001b[38;5;241m3\u001b[39m])]\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# Plot the coefficients\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m    171\u001b[0m plt\u001b[38;5;241m.\u001b[39mbarh(feature_names, importance_values, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m#plt.yticks(range(len(sorted_idx)), np.array(feature_names)[sorted_idx])\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "model.feature_importance_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
